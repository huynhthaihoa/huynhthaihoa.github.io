---
layout: post
title: "Rolling in the Depth"
subtitle: "In-house collection about Depth Estimation"
date:   2025-03-28
categories: [Programming]
tags: [Computer_Vision,English]
permalink: /depth-rolling/
---

# Benchmark (up-to-date)

## Public Benchmark

**Disclaimer**: 

- This is just a benchmark on some standard datasets, which means the model does not necessarily become the actual "SOTA" for in-the-wild applications
- This benchmark focuses on **accuracy** metrics but no **latency** metrics, which are also an essential part of the real-time applications

[Papers with Code - Monocular Depth Estimation](https://paperswithcode.com/task/monocular-depth-estimation)

## Personal Benchmark

[Personal benchmark](https://stellar-message-d73.notion.site/Personal-benchmark-1a8edcef2a19807c841ed22014058849?pvs=4)

---

# Personal Notes

[From depth estimation to Pseudo-LIDAR](https://huynhthaihoa.github.io/depth-pseudolidar/)

<!--[Depth Experiment](https://www.notion.so/Depth-Experiment-15fedcef2a198046aeefe231ed001ae7?pvs=21)-->

[Augmentation techniques for depth model](https://stellar-message-d73.notion.site/Augmentation-techniques-for-depth-model-239bf78641da43b4875e5e1daad2705f?pvs=4)

---

# Prominent Works

These works may not be ‚ÄúSOTA‚Äù on some specific datasets but have a high potential for real-world, in-the-wild applications

### **Depth Any Camera: Zero-Shot Metric Depth Estimation from Any Camera (2025)**

[Depth Any Camera](https://yuliangguo.github.io/depth-any-camera/)

### **Prompting Depth Anything for 4K Resolution Accurate Metric Depth Estimation (2024)**

[https://promptda.github.io/](https://promptda.github.io/)

### Lotus: Diffusion-based Visual Foundation Model for High-quality Dense Prediction (2024)

[Lotus](https://lotus3d.github.io/)

### **World-consistent Video Diffusion with Explicit 3D Modeling (2024)**

[WVD](https://zqh0253.github.io/wvd/)

### **RollingDepth: Video Depth without Video Models (2024)**

[https://github.com/prs-eth/rollingdepth](https://github.com/prs-eth/rollingdepth)

### Depth Anything - CVPR 2024

[https://github.com/DepthAnything/Depth-Anything-V2](https://github.com/DepthAnything/Depth-Anything-V2)

[https://github.com/LiheYoung/Depth-Anything](https://github.com/LiheYoung/Depth-Anything)

### DepthCrafter: Generating Consistent Long Depth Sequences for Open-world Videos (2024)

[https://github.com/Tencent/DepthCrafter](https://github.com/Tencent/DepthCrafter)

### **Depth Anywhere: Enhancing 360 Monocular Depth Estimation via Perspective Distillation and Unlabeled Data Augmentation - Neurips 2024**

[https://github.com/albert100121/Depth-Anywhere](https://github.com/albert100121/Depth-Anywhere)

### **Depth Pro: Sharp Monocular Metric Depth in Less Than a Second (2024)**

[https://github.com/apple/ml-depth-pro](https://github.com/apple/ml-depth-pro)

[https://github.com/apple/ml-depth-pro/issues/1](https://github.com/apple/ml-depth-pro/issues/1)

### **UniDepth: Universal Monocular Metric Depth Estimation - CVPR 2024**

[https://github.com/lpiccinelli-eth/UniDepth](https://github.com/lpiccinelli-eth/UniDepth)

### **Marigold: Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation - CVPR 2024**

[https://github.com/prs-eth/marigold](https://github.com/prs-eth/marigold)

### Booster: A Benchmark for Depth from Images of Specular and Transparent Surfaces (2023)

[arxiv.org](https://arxiv.org/pdf/2301.08245)

### Deep Depth from Focus with Differential Focus Volume  - CVPR 2022

[arxiv.org](https://arxiv.org/pdf/2112.01712)

[https://github.com/fuy34/DFV](https://github.com/fuy34/DFV)

### **Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer (2020)**

[https://github.com/isl-org/MiDaS](https://github.com/isl-org/MiDaS)

---

# Datasets & Simulator

### **RGBD Objects in the Wild: Scaling Real-World 3D Object Learning from RGB-D Videos**

[https://github.com/wildrgbd/wildrgbd](https://github.com/wildrgbd/wildrgbd)

### CARLA Simulator

[https://github.com/carla-simulator/carla](https://github.com/carla-simulator/carla)

---

# Other References

- [Depth perception](https://en.wikipedia.org/wiki/Depth_perception)

- [Metric and Relative Monocular Depth Estimation: An Overview. Fine-Tuning Depth Anything V2 üëê üìö](https://huggingface.co/blog/Isayoften/monocular-depth-estimation-guide)

- [https://github.com/jspenmar/monodepth_benchmark](https://github.com/jspenmar/monodepth_benchmark)
